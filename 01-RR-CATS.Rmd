---
title: "01-RR-CATS"
author: "Anoff Nicholas Cobblah"
date: "July 31, 2018"
output: html_document
  html_document:
    number_sections: yes
    toc: true
    toc_depth: 6
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


This script combines my Word Flagging and KWIC (tokenizer script) methods in order to create an interactive illustration of the frequency with which the terms "cat," "cats," "dog" or "dogs" are referenced in the novels of Charles Dickens. The goal is to answer two questions: which Dickens novel contains the most references to cats, and did Bob's death around 1862 have any influence on appearances of cats in Dickens's novels.

First, we set our parameters. There are several new things to take into account. Firstly, it is helpful to have three types of conlength values for Key Words in Context. Since the goal is to create a plot which allows KWIC to appear on rollover, 250 words is a bit much. So we have three conlengths of 250, 10, and 3 words.

**It's also important to note that since the creation of the KWIC script takes a long time, I've included a logical switch to make sure it will only create a new dataset if the "raw" data is changed. So the script is set not to run unless it senses a change in the number of bytes, or if the last created dataset is missing.**

```{r DecDCATSApp Parameters, eval=FALSE}
    DCATSlocation <- getwd()
    DCATSdoclocation <- paste0(getwd(),"/Novels")
    DCATSlongconlength <- 250
    DCATSshortconlength <- 3
    DCATSPOSconlength <- 10
    DCATScatsearchedtermlist <- c("cat")
    DCATSdogsearchedtermlist <- c("dog")
    DCATSsearchedtermlist <- c(DCATScatsearchedtermlist,DCATSdogsearchedtermlist)
    DCATSoutputlocation <- paste0(getwd(),"/WordFlagDataFrames")
    DCATSWordFlagdfPath <- paste0(DCATSoutputlocation,"/","DCATSWordFlagdf.txt")
    DCATSDocumentSize <- 32691727
```

To create the data frame compiling every reference to a term, or to upload the last version of that dataset, run the following script. Note that because this takes takes a long time to run, the dataset is always saved and called back up if possible.

```{r DecDCATSApp Word Flag, eval=FALSE}
      if(sum(file.info(list.files(DCATSdoclocation, all.files = TRUE, recursive = TRUE, full.names=TRUE))$size) == DCATSDocumentSize) {
        DCATSDataChange1 <- FALSE
        print("The data in the 'Documents' folder appears not to have changed.")
      }else{
        DCATSDataChange1 <- TRUE
        print("The data in the 'Documents' folder appears to have been changed. A new DCATSWordFlagdf will therefore be created. TO UPDATE THIS SCRIPT, PLEASE CHANGE THE DCATSDocumentSize TO REFLECT THE NEW SIZE OF THE DOCUMENTS.")
        }
      
      if(file.exists(DCATSWordFlagdfPath) == TRUE) {
        DCATSDataChange2 <- FALSE
        print("The previous DCATSWordFlagdf still exists.")
      }else{
        DCATSDataChange2 <- TRUE
        print("The previous DCATSwordFlagdf seems to have been moved or deleted.  A new DCATSWordFlag will therefore be created.")
        }

  if(DCATSDataChange1|DCATSDataChange2 == TRUE) {
  
      files <- list.files(path = DCATSdoclocation, pattern = "xml", full.names = TRUE) #creates vector of txt file names.
      if(file.exists(DCATSoutputlocation) == FALSE){dir.create(DCATSoutputlocation)}
      DCATSstemsearchedtermlist <- unique(wordStem(DCATSsearchedtermlist)) #lemmatizes the list of terms you want to search for.
      DCATSWordFlagmat <- matrix(,ncol=12,nrow=1)
      for (i in 1:length(files)) {
        fileName <- read_file(files[i])
        Encoding(fileName) <- "UTF-8"  #since tokenize_sentences function requires things to be encoded in UTF-8, need to remove some data.
        fileName <- iconv(fileName, "UTF-8", "UTF-8",sub='')
        ltoken <- tokenize_words(fileName, lowercase = TRUE, stopwords = NULL, simplify = FALSE)
        ltoken <- unlist(ltoken)
        stemltoken <- wordStem(ltoken) #this uses the Snowball library to lemmatize the entire text.
        textID <- i
        for (p in 1:length(DCATSstemsearchedtermlist)) {
          DCATSstemsearchedterm <- DCATSstemsearchedtermlist[p]
          for (j in 1:length(stemltoken)) {
              if (DCATSstemsearchedterm == stemltoken[j]) {
                if (j <= DCATSlongconlength) {longtempvec <- ltoken[(1:(j+DCATSlongconlength))]}
                if (j > DCATSlongconlength) {longtempvec <- ltoken[(j-DCATSlongconlength):(j+DCATSlongconlength)]}
                if (j <= DCATSshortconlength) {shorttempvec <- ltoken[(1:(j+DCATSshortconlength))]}
                if (j > DCATSshortconlength) {shorttempvec <- ltoken[(j-DCATSshortconlength):(j+DCATSshortconlength)]}
                if (j <= DCATSPOSconlength) {POStempvec <- ltoken[(1:(j+DCATSPOSconlength))]}
                if (j > DCATSPOSconlength) {POStempvec <- ltoken[(j-DCATSPOSconlength):(j+DCATSPOSconlength)]}
                TempTextName <- gsub(paste0(DCATSdoclocation,"/"),"",files[i]) #This grabs just the end of the file path.
                TempTextName <- gsub(".txt","",TempTextName) #This removes the .txt from the end of the name.
                temprow <- matrix(,ncol=12,nrow=1)
                colnames(temprow) <- c("Text", "Text_ID", "DCATSstemsearchedterm","Lemma","Lemma_Perc","KWIC","Total_Lemma","Date","Category","Short_KWIC","POS_KWIC","Current_Date")
                temprow[1,1] <- TempTextName
                temprow[1,2] <- textID
                temprow[1,3] <- DCATSstemsearchedterm
                temprow[1,4] <- j
                temprow[1,5] <- (j/length(stemltoken))*100
                temprow[1,6] <- as.character(paste(longtempvec,sep= " ",collapse=" "))
                temprow[1,7] <- length(stemltoken)
                temprow[1,8] <- strsplit(TempTextName,"_")[[1]][1]
                #Determining Category
                  if(DCATSstemsearchedterm %in% wordStem(DCATScatsearchedtermlist)) {temprow[1,9] <- "cat-Rhetoric"}
                  if(DCATSstemsearchedterm %in% wordStem(DCATSdogsearchedtermlist)) {temprow[1,9] <- "dog-Rhetoric"}
                temprow[1,10] <- as.character(paste(shorttempvec,sep= " ",collapse=" "))
                temprow[1,11] <- as.character(paste(POStempvec,sep= " ",collapse=" "))
                temprow[1,12] <- format(Sys.time(), "%Y-%m-%d")
                DCATSWordFlagmat <- rbind(DCATSWordFlagmat,temprow)
              }
          }
        }
        print(files[i]) #let's user watch as code runs for long searches
      }
      DCATSWordFlagmat <- DCATSWordFlagmat[-1,]
      DCATSWordFlagdf <- as.data.frame(DCATSWordFlagmat)
      write.table(DCATSWordFlagdf, DCATSWordFlagdfPath)
      DCATSWordFlagdf[1:5,]
  }else{
    print("Loading the previous dataset as DCATSWordFlagdf")
    DCATSWordFlagdf <- read.table(DCATSWordFlagdfPath)
  }
DCATSWordFlagdf
```

We can then add up the values in DCATSWordFlagdf to make a table of the frequency of cat and dog rhetoric, DCATSFreqmat. This step is important because we also introduce a new column: "Sample_KWIC", which randomly chooses one example of Key Words in Context.
```{r,  eval=FALSE}
  # Adding values from DCATSWordFlagdf together to get a matrix of normalized frequencies for each category, as DCATSFreqmat
      DCATSWordFlagcatdf <- DCATSWordFlagdf[grep("cat-Rhetoric",DCATSWordFlagdf$Category),]
      DCATSWordFlagdogdf <- DCATSWordFlagdf[grep("dog-Rhetoric",DCATSWordFlagdf$Category),]
      DCATSFreqmat <- matrix(,ncol=8,nrow=1)
      files <- list.files(path = DCATSdoclocation, pattern = "txt", full.names = TRUE) #creates vector of txt file names.
      for (i in 1:length(files)) {
        TempTextName <- gsub(paste0(DCATSdoclocation,"/"),"",files[i]) #This grabs just the end of the file path.
        TempTextName <- gsub(".txt","",TempTextName) #This removes the .txt from the end of the name.
        tempcatdf <- DCATSWordFlagcatdf[grep(TempTextName,DCATSWordFlagcatdf$Text),]
        tempdogdf <- DCATSWordFlagdogdf[grep(TempTextName,DCATSWordFlagdogdf$Text),]
        TempDate <- strsplit(TempTextName,"_")[[1]][1]
        TempLength <- tempcatdf$Total_Lemma[1]
        temprows <- matrix(,ncol=8,nrow=2)
        colnames(temprows) <- c("Text", "Text_ID","Date","Category","Frequency","Total_Lemma","Normalized_Freq","Sample_KWIC")
        temprows[1:2,1] <- as.character(TempTextName)
        temprows[1:2,2] <- i
        temprows[1:2,3] <- as.character(TempDate)
        temprows[1,4] <- "cat-Rhetoric"
        temprows[2,4] <- "dog-Rhetoric"
        temprows[1,5] <- nrow(tempcatdf)
        temprows[2,5] <- nrow(tempdogdf)
        temprows[1:2,6]<- as.character(TempLength)
        temprows[1,7] <- (as.numeric(temprows[1,5])/as.numeric(temprows[1,6]))*100
        temprows[2,7] <- (as.numeric(temprows[2,5])/as.numeric(temprows[2,6]))*100
        #temprows[1,8]
          if(nrow(tempcatdf) > 0){temprows[1,8] <- as.character(sample(tempcatdf$Short_KWIC,1))}else{temprows[1,8] <- NA}
        #temprows[2,8]
          if(nrow(tempdogdf) >0) {temprows[2,8] <- as.character(sample(tempdogdf$Short_KWIC,1))}else{temprows[2,8] <- NA}
        DCATSFreqmat <- rbind(DCATSFreqmat,temprows)
      }
      DCATSFreqmat <- DCATSFreqmat[-1,]
      DCATSFreqdf <- as.data.frame(DCATSFreqmat)
      DCATSWordFlagdf$KWIC = as.character(DCATSWordFlagdf$KWIC)
      DCATSWordFlagdf$Text = as.character(DCATSWordFlagdf$Text)
      DCATSFreqdf

```

We can then answer questions using DCATSFreqdf.  For instance, we can see that dog rhetoric rises in *Reports* over time.

```{r DCATSFreqmat by date,  eval=FALSE}
      
  # Visualizing DCATSFreqdf
      p <- ggplot(DCATSFreqdf, aes(y = as.numeric(as.character(Normalized_Freq)), x = as.numeric(as.character(Date)), color = Category))
      pg <- geom_point(size=1,pch = 16)
      pl <- p + pg + labs(x = "Date", y = "Normalized Frequency (% of Words in Text)", title = "Appearances of cat and dog Rhetoric within Reports of the DCATS")
      pl
```

Or we can create an interactive graph that shows us an example key word in context from that year on rollover.

```{r DCATSFreqmat by date interactive,  eval=FALSE}
      
  # Visualizing DCATSFreqdf
      p <- ggplot(DCATSFreqdf, aes(y = as.numeric(as.character(Normalized_Freq)), x = as.numeric(as.character(Date)), color = Category, label = Sample_KWIC))
      pg <- geom_point(size=1,pch = 16)
      pl <- p + pg + labs(x = "Date", y = "Normalized Frequency (% of Words in Text)", title = "Appearances of cat and dog Rhetoric within \nReports of the DCATS")
      ggplotly(pl)

```

But as Tufte points out, time-series graphics are not good indicators of cause. For instance, even though intuition might tell us that cat rhetoric would decrease when dog rhetoric increases, I don't THINK that's the case here. But we should check, by charting cat values on the x axis and corresponding dog values on the y axis.
```{r DCATS causality, eval=FALSE}
#first we create a slightly different version of DCATSFreqmat
      DCATSWordFlagcatdf <- DCATSWordFlagdf[grep("cat-Rhetoric",DCATSWordFlagdf$Category),]
      DCATSWordFlagdogdf <- DCATSWordFlagdf[grep("dog-Rhetoric",DCATSWordFlagdf$Category),]
      NewDCATSFreqmat <- matrix(,ncol=8,nrow=1)
      files <- list.files(path = DCATSdoclocation, pattern = "txt", full.names = TRUE) #creates vector of txt file names.
      for (i in 1:length(files)) {
        TempTextName <- gsub(paste0(DCATSdoclocation,"/"),"",files[i]) #This grabs just the end of the file path.
        TempTextName <- gsub(".txt","",TempTextName) #This removes the .txt from the end of the name.
        tempcatdf <- DCATSWordFlagcatdf[grep(TempTextName,DCATSWordFlagcatdf$Text),]
        tempdogdf <- DCATSWordFlagdogdf[grep(TempTextName,DCATSWordFlagdogdf$Text),]
        TempDate <- strsplit(TempTextName,"_")[[1]][1]
        TempLength <- tempcatdf$Total_Lemma[1]
        temprows <- matrix(,ncol=8,nrow=1)
        colnames(temprows) <- c("Text", "Text_ID","Date","cat_Freq","dog_Freq","Total_Lemma","cat_Norm_Freq","dog_Norm_Freq")
        temprows[1,1] <- as.character(TempTextName)
        temprows[1,2] <- i
        temprows[1,3] <- as.character(TempDate)
        temprows[1,4] <- nrow(tempcatdf)
        temprows[1,5] <- nrow(tempdogdf)
        temprows[1,6]<- as.character(TempLength)
        temprows[1,7] <- (as.numeric(temprows[1,4])/as.numeric(temprows[1,6]))*100
        temprows[1,8] <- (as.numeric(temprows[1,5])/as.numeric(temprows[1,6]))*100
        NewDCATSFreqmat <- rbind(NewDCATSFreqmat,temprows)
      }
      NewDCATSFreqmat <- NewDCATSFreqmat[-1,]
      NewDCATSFreqdf <- as.data.frame(NewDCATSFreqmat)
      NewDCATSFreqdf
      #I want to add another column so I can add a third variable of date, aligned with the darkness of the dots.
      NewDCATSFreqdf$Year <- as.numeric(as.character(NewDCATSFreqdf$Date))
      
      p <- ggplot(NewDCATSFreqdf, aes(y = as.numeric(as.character(dog_Norm_Freq)), x = as.numeric(as.character(cat_Norm_Freq)), alpha = Year))
      pg <- geom_point(size=1,pch = 16)
      pl <- p + pg + labs(x = "Normalized Frequency of 'cat' (% of Words in Volume)", y = "Normalized Frequency of 'dog,' 'doger,' \nand 'Labor' (% of Words in Volume)", title = "Appearances of Cat and dog Rhetoric within Reports of the DCATS")
      pl
```

We can also visualize the terms which most frequently occur around the search terms in the two categories within this corpus.
```{r DCATS dog/cat associations,  eval=FALSE}
corpus <- corpus(DCATSWordFlagdf, 
                 docid_field="Text", 
                 text_field="KWIC")
group_DCATSWordFlagdfm <- dfm(corpus, remove=c(stopwords("en"),DCATSsearchedtermlist), remove_punct=TRUE, remove_numbers = TRUE, groups="Category")
textplot_wordcloud(group_DCATSWordFlagdfm,max.words=50, colors = RColorBrewer::brewer.pal(8,"Dark2"), comparison=TRUE)


```

Finally, we can run a very rudimentary qualitative sentiment analysis by looking at JUST the adjectives which appear around the term (for instance, within a 10 word range on either side). This requires part of speech (POS) tagging, which can take a very long time, which is why we are doging from the "POS_KWIC" column of "DCATSWordFlagdf." This also requires the use of the coreNLP library, which can take a long time to install and initialize, So this section has an extra parameter to initialize it.  

**If you want to run a POS tagging script to view the most common adjectives and adverbs that accompany cat and dog rhetoric in the corpus, enter "DECDCATSPOSApp <- TRUE" BELOW.**

**IMPORTANT NOTE: Since creating a Word Flag matrix can take a nontrivial amount of time for larger corpuses, this script is designed only to run the program to create a new DCATSWordFlagdf if there is a change to the dataset in folder "Documents" or if the previous DCATSKWICPOScatdf and DCATSKWICPOSdogdf has been deleted.**

First, we add a few more parameters determining what the output will be saved as.
```{r DECDCATSPOSApp parameter,  eval=FALSE}
    DCATSKWICPOScatdfPath <- paste0(DCATSoutputlocation,"/","DCATSKWICPOScatdf.txt")
    DCATSKWICPOSdogdfPath <- paste0(DCATSoutputlocation,"/","DCATSKWICPOSdogdf.txt")
```

Then we run a script to create dataset which identify and mark each of the adjectives and adverbs in our Key Words in context (the 10 word range one, as otherwise this quickly gets out of hand.)

```{r DECDCATSPOSApp,  eval=FALSE}
   if(file.exists(DCATSKWICPOScatdfPath)&file.exists(DCATSKWICPOSdogdfPath) == TRUE) {
        DCATSDataChange3 <- FALSE
        print("The previous DCATSWordFlagdf still exists.")
      }else{
        DCATSDataChange3 <- TRUE
        print("The previous DCATSKWICPOScatdf or DCATSKWICPOSdogdf seems to have been moved or deleted.  A new DCATSKWICPOSdf will therefore be created.")
        }
  
  if(DCATSDataChange1|DCATSDataChange3 == TRUE) {
    #we run part of speech tagging on each of these KWIC and draw out just the adjectives, and sum up the numbers.
      #We do this for the cat rhetoric data.
        ADJADVcatdf <- data.frame( Var1=character(),Freq=numeric())
        for(i in 1:nrow(DCATSWordFlagcatdf)) {
          tempstring <- as.character(DCATSWordFlagcatdf$POS_KWIC[i])
          anno <- annotateString(tempstring)
          token <- getToken(anno)
          ut <- universalTagset(token$POS)
          index <- c(which(ut=="ADJ"), which(ut=="ADV"))
          temptable <- table(token$lemma[index])
          ADJADVcatdf <- rbind(ADJADVcatdf,as.data.frame(temptable))
          print(i)
        }
        ADJADVcatdf <- aggregate(ADJADVcatdf$Freq, b=list(Category=ADJADVcatdf$Var1), FUN=sum)
        DCATSKWICPOScatdf <- ADJADVcatdf[order(ADJADVcatdf$x, decreasing=TRUE),]  #reordering the matrix
        write.table(DCATSKWICPOScatdf, DCATSKWICPOScatdfPath)
        
      #And for the dog rhetoric data.
        ADJADVdogdf <- data.frame( Var1=character(),Freq=numeric())
        for(i in 1:nrow(DCATSWordFlagdogdf)) {
          tempstring <- as.character(DCATSWordFlagdogdf$POS_KWIC[i])
          anno <- annotateString(tempstring)
          token <- getToken(anno)
          ut <- universalTagset(token$POS)
          index <- c(which(ut=="ADJ"), which(ut=="ADV"))
          temptable <- table(token$lemma[index])
          ADJADVdogdf <- rbind(ADJADVdogdf,as.data.frame(temptable))
          print(i)
        }
        ADJADVdogdf <- aggregate(ADJADVdogdf$Freq, b=list(Category=ADJADVdogdf$Var1), FUN=sum)
        DCATSKWICPOSdogdf <- ADJADVdogdf[order(ADJADVdogdf$x, decreasing=TRUE),]  #reordering the matrix
        write.table(DCATSKWICPOSdogdf, DCATSKWICPOSdogdfPath)
  }else{
    print("Loading the previous datasets as DCATSKWICPOScatdf and DCATSKWICPOSdogdf")
    DCATSKWICPOScatdf <- read.table(DCATSKWICPOScatdfPath)
    DCATSKWICPOSdogdf <- read.table(DCATSKWICPOSdogdfPath)
  }
    DCATSKWICPOScatdf
    DCATSKWICPOSdogdf
```

Finally, we visualize the top 25 adjectives and adverbs in these KWIC sets. In this case, we don't learn very much, unfortunately.

```{r DECDCATSPOSApp Visualized,  eval=FALSE}
        TopADJADVcatdf <- DCATSKWICPOScatdf[1:25,]
        TopADJADVcatdf$Category <- factor(TopADJADVcatdf$Category, levels = TopADJADVcatdf$Category[order(TopADJADVcatdf$x)])
        TopADJADVdogdf <- DCATSKWICPOSdogdf[1:25,]
        TopADJADVdogdf$Category <- factor(TopADJADVdogdf$Category, levels = TopADJADVdogdf$Category[order(TopADJADVdogdf$x)])
    
        #Then we visualize the top 25 adjectives and adverbs for dog and cat rhetoric.
           p1 <- ggplot(TopADJADVcatdf, aes(y = as.numeric(as.character(x)), x = (Category)))
           p2 <- geom_bar(stat="identity") 
           p3 <- p1 + p2 + labs(x = "Adjective/Adverb near cat Rhetoric", y = "Frequency", title = "Common Adjectives and Adverbs near cat Rhetoric \nwithin Reports of the DCATS")
           pl1 <- p3+coord_flip()
          
            p4 <- ggplot(TopADJADVdogdf, aes(y = as.numeric(as.character(x)), x = (Category)))
           p5 <- geom_bar(stat="identity") 
           p6 <- p4 + p5 + labs(x = "Adjective/Adverb near cat Rhetoric", y = "Frequency", title = "Common Adjectives and Adverbs near dog Rhetoric \nwithin Reports of the DCATS")
           pl2 <- p6+coord_flip()
           {print(pl1)
           print(pl2)}
```
